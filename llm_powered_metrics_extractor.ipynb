{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2SYjMr-L77g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from datetime import datetime, timedelta\n",
        "from dotenv import load_dotenv\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import json\n",
        "\n",
        "# Load environment variables from the .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Get the OpenAI API key from environment variable\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# FastAPI initialization\n",
        "app = FastAPI()\n",
        "\n",
        "# Define a request model for the query\n",
        "class QueryRequest(BaseModel):\n",
        "    query: str\n",
        "\n",
        "# Function to get default start and end dates (past one year from today)\n",
        "def get_default_dates():\n",
        "    \"\"\"\n",
        "    Returns the default start and end date as ISO 8601 format.\n",
        "    Start date: One year from today\n",
        "    End date: Today's date\n",
        "    \"\"\"\n",
        "    today = datetime.today()\n",
        "    last_year = today - timedelta(days=365)\n",
        "    return last_year.isoformat()[:10], today.isoformat()[:10]\n",
        "\n",
        "# Function to reformat the user's query for the model\n",
        "def reformat_query_for_model(user_query):\n",
        "    \"\"\"\n",
        "    Reformat the user's query to instruct the language model (LLM) to return the response\n",
        "    in JSON format, extracting company names (entities), performance metrics, and dates.\n",
        "    If no dates are provided, it uses the default date range.\n",
        "\n",
        "    Args:\n",
        "    user_query (str): The natural language query from the user.\n",
        "\n",
        "    Returns:\n",
        "    str: Reformatted query to be sent to the LLM.\n",
        "    \"\"\"\n",
        "    start_date, end_date = get_default_dates()\n",
        "\n",
        "    # Reformat the user's query for multiple entities and to extract relevant data\n",
        "    reformatted_query = f\"\"\"\n",
        "    User Query: \"{user_query}\"\n",
        "\n",
        "    Please extract all company names (entities), performance metrics (parameters), and time ranges.\n",
        "    If the start date or end date is missing, assume the date range is from {start_date} to {end_date}.\n",
        "\n",
        "    Return the result in the following JSON format, with multiple companies if applicable:\n",
        "    [\n",
        "        {{\n",
        "            \"entity\": \"<company_name>\",\n",
        "            \"parameter\": \"<metric_name>\",\n",
        "            \"startDate\": \"<start_date_iso>\",\n",
        "            \"endDate\": \"<end_date_iso>\"\n",
        "        }},\n",
        "        ...\n",
        "    ]\n",
        "    \"\"\"\n",
        "    return reformatted_query\n",
        "\n",
        "# Function to call OpenAI GPT to process the query\n",
        "def query_openai_model(reformatted_query):\n",
        "    \"\"\"\n",
        "    Sends the reformatted query to OpenAI GPT model and returns the generated response.\n",
        "\n",
        "    Args:\n",
        "    reformatted_query (str): The reformatted query to be processed by GPT.\n",
        "\n",
        "    Returns:\n",
        "    str: Generated text from the model.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            model=\"gpt-3.5-turbo\",  # Or use \"gpt-4\" if available\n",
        "            prompt=reformatted_query,\n",
        "            max_tokens=150\n",
        "        )\n",
        "        return response['choices'][0]['text']  # Extract the generated text\n",
        "    except openai.error.OpenAIError as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"OpenAI API error: {str(e)}\")\n",
        "\n",
        "# Function to validate the model's response to ensure it is in valid JSON format\n",
        "def validate_response(model_response):\n",
        "    \"\"\"\n",
        "    Validates the model's response to ensure it is a valid JSON object or list of objects.\n",
        "\n",
        "    Args:\n",
        "    model_response (str): The response from the model.\n",
        "\n",
        "    Returns:\n",
        "    dict or list: Parsed JSON data.\n",
        "\n",
        "    Raises:\n",
        "    ValueError: If the model response is not valid JSON or is missing required fields.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Try parsing the model's response as JSON\n",
        "        parsed_response = json.loads(model_response)\n",
        "\n",
        "        # Check if it is a list and has required fields for each entry\n",
        "        if isinstance(parsed_response, list):\n",
        "            for item in parsed_response:\n",
        "                if not all(key in item for key in [\"entity\", \"parameter\", \"startDate\", \"endDate\"]):\n",
        "                    raise ValueError(\"Response is missing required fields\")\n",
        "            return parsed_response\n",
        "        else:\n",
        "            raise ValueError(\"Expected a list of JSON objects\")\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        raise ValueError(\"Model did not return valid JSON\")\n",
        "\n",
        "# Function to process the user's query and extract metrics\n",
        "def process_query(query):\n",
        "    \"\"\"\n",
        "    Processes the user's query, sends it to the LLM, and validates the response.\n",
        "\n",
        "    Args:\n",
        "    query (str): The user's query in natural language.\n",
        "\n",
        "    Returns:\n",
        "    dict or list: Structured JSON response from the model.\n",
        "\n",
        "    Raises:\n",
        "    HTTPException: For validation errors or API errors.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Reformat the query for the model\n",
        "        reformatted_query = reformat_query_for_model(query)\n",
        "\n",
        "        # Send the reformatted query to the model and get the response\n",
        "        model_response = query_openai_model(reformatted_query)\n",
        "\n",
        "        # Validate and parse the response\n",
        "        validated_response = validate_response(model_response)\n",
        "        return validated_response\n",
        "\n",
        "    except ValueError as e:\n",
        "        raise HTTPException(status_code=400, detail=str(e))\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=\"Internal Server Error\")\n",
        "\n",
        "# FastAPI route to handle POST requests\n",
        "@app.post(\"/extract-metrics\")\n",
        "async def extract_metrics(request: QueryRequest):\n",
        "    \"\"\"\n",
        "    API endpoint to extract metrics from a user query.\n",
        "\n",
        "    Args:\n",
        "    request (QueryRequest): The user query sent via POST request.\n",
        "\n",
        "    Returns:\n",
        "    JSON: Extracted company names, performance metrics, and time range in JSON format.\n",
        "    \"\"\"\n",
        "    query = request.query\n",
        "    result = process_query(query)\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Features:\n",
        "\n",
        "1. **Correctness of the JSON Output:**\n",
        "    - The model is instructed to return output in a structured JSON format, which is then validated using the `validate_response()` function.\n",
        "    - The response is checked to ensure that it contains all the required fields (`entity`, `parameter`, `startDate`, and `endDate`).\n",
        "2. **Proper Handling of Default Start and End Dates:**\n",
        "    - The `get_default_dates()` function handles cases where the user does not explicitly provide a start or end date, defaulting to a one-year range.\n",
        "    - The default date range is embedded directly into the query reformatting process, ensuring it's applied automatically when missing.\n",
        "3. **Handling Multiple Companies and Comparison Requests:**\n",
        "    - The query is reformatted to instruct the model to handle multiple companies and return a list of results for each entity in the request. This enables easy comparisons between multiple companies within the same request.\n",
        "    - Example query: `\"Compare Amazon and Google revenue for 2021.\"`\n",
        "4. **Code Quality, Readability, and Documentation:**\n",
        "    - The code has been improved with detailed docstrings and comments explaining each functionâ€™s purpose and logic.\n",
        "    - The logic is modular, ensuring that each function handles a specific task (e.g., query reformatting, sending API requests, validating responses).\n",
        "5. **Effective Use of the LLM for Understanding User Queries:**\n",
        "    - The LLM is instructed explicitly to extract entities and performance metrics. By giving it clear instructions to return a JSON object, it simplifies post-processing and reduces errors.\n",
        "    - Proper handling of entity extraction, metric extraction, and date parsing is ensured by guiding the model with a well-formatted prompt.\n",
        "6. **Error Handling and Robustness:**\n",
        "    - API errors, JSON parsing errors, and validation failures are properly handled using Python exceptions. The application raises appropriate HTTP exceptions with detailed messages when something goes wrong.\n",
        "    - Both client errors (bad requests) and server errors (internal server issues) are captured, making the application resilient in various failure scenarios.\n",
        "\n",
        "### Example Query:\n",
        "\n",
        "**User Query:**\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"query\": \"What was Amazon and Google's revenue in 2021?\"\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "**Response (Expected JSON):**\n",
        "\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"entity\": \"Amazon\",\n",
        "        \"parameter\": \"revenue\",\n",
        "        \"startDate\": \"2021-01-01\",\n",
        "        \"endDate\": \"2021-12-31\"\n",
        "    },\n",
        "    {\n",
        "        \"entity\": \"Google\",\n",
        "        \"parameter\": \"revenue\",\n",
        "        \"startDate\": \"2021-01-01\",\n",
        "        \"endDate\": \"2021-12-31\"\n",
        "    }\n",
        "]\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "3dwIJ77DMC-6"
      }
    }
  ]
}